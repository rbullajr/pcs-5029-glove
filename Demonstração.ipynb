{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZcZqKt40c3W"
   },
   "source": [
    "# Global Vectors for Word Representation (GloVe)\n",
    "\n",
    "Autores:\n",
    "*   Rafael Noboro Tominaga\n",
    "*   Romeo Bulla Junior\n",
    "\n",
    "Disciplina:\n",
    "*   Processamento de Linguagem Natural com Redes Neurais Artificiais (PCS5029)\n",
    "\n",
    "Docente:\n",
    "*   Prof. Dr. Edson Satoshi Gomi\n",
    "\n",
    "Objetivo:\n",
    "*   Apresentar o modelo GloVe e comparar com Skip‑gram (SG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12757,
     "status": "ok",
     "timestamp": 1759515281553,
     "user": {
      "displayName": "Rafael Noboro Tominaga",
      "userId": "12580002376241615803"
     },
     "user_tz": 180
    },
    "id": "UBzBxXudR2Ca",
    "outputId": "70da91a6-90dc-42d0-fba0-74ee99a57f52"
   },
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4104,
     "status": "ok",
     "timestamp": 1759515285664,
     "user": {
      "displayName": "Rafael Noboro Tominaga",
      "userId": "12580002376241615803"
     },
     "user_tz": 180
    },
    "id": "AQwNIMn13CFS"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapi\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLr--YVQ2HqN"
   },
   "source": [
    "# Introdução\n",
    "\n",
    "Word2Vec (Mikolov et al., 2013) possui duas variantes:\n",
    "\n",
    "*   CBOW (Continuous Bag of Words): prediz a palavra central a partir do contexto. É rápido, funciona bem para palavras frequentes, mas tende a suavizar representações e perde nuances.\n",
    "\n",
    "*   Skip‑gram (SG): prediz palavras de contexto a partir da palavra central. Funciona melhor para palavras raras e nuances semânticas, mas é mais lento.\n",
    "\n",
    "GloVe (Pennington, Socher e Manning, 2014) foi proposto para superar essas limitações, combinando o melhor dos dois mundos:\n",
    "\n",
    "*   Usa estatísticas globais de co‑ocorrência (não apenas janelas locais de contexto).\n",
    "\n",
    "*   Produz embeddings consistentes para tarefas semânticas (analogias, relações globais) e sintáticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 500877,
     "status": "ok",
     "timestamp": 1759515786545,
     "user": {
      "displayName": "Rafael Noboro Tominaga",
      "userId": "12580002376241615803"
     },
     "user_tz": 180
    },
    "id": "9AQJ1OC1Eujj",
    "outputId": "3e60be9f-a8b3-415e-c380-4fa8d461b9ab"
   },
   "outputs": [],
   "source": [
    "model_glove = api.load(\"glove-wiki-gigaword-300\")\n",
    "model_sg = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3UvRFYN3X6f"
   },
   "source": [
    "# Comparação de vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759515786559,
     "user": {
      "displayName": "Rafael Noboro Tominaga",
      "userId": "12580002376241615803"
     },
     "user_tz": 180
    },
    "id": "It2zEL2m3fzW",
    "outputId": "0b08e4a8-d15a-4381-a534-bb6177d8fafa"
   },
   "outputs": [],
   "source": [
    "word = \"apple\"\n",
    "print(\"GloVe:\", model_glove.most_similar(word, topn=5))\n",
    "print(\"Skip-gram:\", model_sg.most_similar(word, topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBRd9okHnHvL"
   },
   "source": [
    "# Teste de analogias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759515786568,
     "user": {
      "displayName": "Rafael Noboro Tominaga",
      "userId": "12580002376241615803"
     },
     "user_tz": 180
    },
    "id": "bQzaSRyMmJJZ",
    "outputId": "b9df341d-20fb-4387-d592-e4f85a720e3c"
   },
   "outputs": [],
   "source": [
    "print(\"GloVe:\", model_glove.most_similar(positive=[\"king\",\"woman\"], negative=[\"man\"], topn=5))\n",
    "print(\"Skip-gram:\", model_sg.most_similar(positive=[\"king\",\"woman\"], negative=[\"man\"], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PCyJI_1nKmy"
   },
   "source": [
    "# Visualização com PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1759515786586,
     "user": {
      "displayName": "Rafael Noboro Tominaga",
      "userId": "12580002376241615803"
     },
     "user_tz": 180
    },
    "id": "0o3ubfsfmVFF",
    "outputId": "5c6d6a4c-62e7-46eb-b34e-8ec91ab98c77"
   },
   "outputs": [],
   "source": [
    "def plot_embeddings(model, words, title):\n",
    "    vectors = [model[w] for w in words if w in model]\n",
    "    pca = PCA(n_components=2)\n",
    "    coords = pca.fit_transform(vectors)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(coords[:,0], coords[:,1], c='blue')\n",
    "    for word, (x,y) in zip(words, coords):\n",
    "        plt.text(x+0.02, y+0.02, word, fontsize=12)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "words = [\"king\", \"queen\", \"man\", \"woman\", \"prince\", \"princess\", \"lord\", \"lady\"]\n",
    "\n",
    "print(\"\\nVisualização PCA (GloVe):\")\n",
    "plot_embeddings(model_glove, words, \"Espaço vetorial - GloVe\")\n",
    "\n",
    "print(\"Visualização PCA (Skip-gram):\")\n",
    "plot_embeddings(model_sg, words, \"Espaço vetorial - Skip-gram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEnRfLBenQM2"
   },
   "source": [
    "# Comparação de similaridade em pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759515786594,
     "user": {
      "displayName": "Rafael Noboro Tominaga",
      "userId": "12580002376241615803"
     },
     "user_tz": 180
    },
    "id": "g_l9ofa4m1tH",
    "outputId": "0fb4202c-770c-4540-d510-752c78bad26b"
   },
   "outputs": [],
   "source": [
    "pairs = [(\"king\",\"queen\"), (\"man\",\"woman\"), (\"paris\",\"france\"), (\"rome\",\"italy\"), (\"car\",\"road\"), (\"cat\",\"dog\")]\n",
    "\n",
    "print(\"\\nSimilaridade coseno para pares de palavras:\\n\")\n",
    "for w1, w2 in pairs:\n",
    "    if w1 in model_glove and w2 in model_glove and w1 in model_sg and w2 in model_sg:\n",
    "        sim_glove = model_glove.similarity(w1,w2)\n",
    "        sim_sg = model_sg.similarity(w1,w2)\n",
    "        print(f\"{w1}-{w2}:  GloVe={sim_glove:.3f},  Skip-gram={sim_sg:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPPrQHVkvyju+S1YbGyLma",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
